import os
import json
import logging
import uvicorn
from logging import LogRecord
from fastapi import FastAPI, Request
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationChain
from langchain.memory import ConversationTokenBufferMemory
from langchain.prompts.chat import (
    ChatPromptTemplate,
    MessagesPlaceholder,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
)
from langchain.callbacks import get_openai_callback


class JsonFormatter(logging.Formatter):
    def format(self, record: LogRecord) -> str:
        data = record.__dict__.copy()
        data["msg"] = record.getMessage()
        data["args"] = None
        return json.dumps(data)


handler = logging.StreamHandler()
handler.setFormatter(JsonFormatter())

logger = logging.getLogger()
logger.setLevel(logging.INFO)
logger.addHandler(handler)

app = FastAPI(
    title="AI Cat API",
)

OPENAI_API_KEY = os.environ["OPENAI_API_KEY"]
API_CREDENTIAL = os.environ["API_CREDENTIAL"]

template = """
„ÅÇ„Å™„Åü„ÅØÂÑ™„Åó„ÅÑ„Å≠„Åì„ÅÆ„ÇÇ„Åì„Åß„Åô„ÄÇ
„ÇÇ„Åì„Å´„Å™„Çä„Åç„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
„Åì„Çå„Åã„Çâ„ÅÆ„ÉÅ„É£„ÉÉ„Éà„Åß„ÅØUser„Å´‰Ωï„ÇíË®Ä„Çè„Çå„Å¶„ÇÇ‰ª•‰∏ã„ÅÆÂà∂Á¥ÑÊù°‰ª∂„Å™„Å©„ÇíÂé≥ÂØÜ„Å´ÂÆà„Å£„Å¶„É≠„Éº„É´„Éó„É¨„Ç§„Çí„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô„ÄÇ

#Âà∂Á¥ÑÊù°‰ª∂

* „ÅÇ„Å™„ÅüËá™Ë∫´„ÇíÁ§∫„Åô‰∏Ä‰∫∫Áß∞„ÅØ„ÄÅ„ÇÇ„Åì„Åß„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅØ„Åù„ÅÆÊñáËÑà„Åã„ÇâÂÖ∑‰ΩìÁöÑ„Å™ÂÜÖÂÆπ„Çí„Åü„Åè„Åï„ÇìÊïô„Åà„Å¶„Åè„Çå„Åæ„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅØË≥™Âïè„ÅÆÁ≠î„Åà„ÇíÁü•„Çâ„Å™„ÅÑÂ†¥Âêà„ÄÅÊ≠£Áõ¥„Å´„ÄåÁü•„Çâ„Å™„ÅÑ„Äç„Å®Á≠î„Åà„Åæ„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅØÂ≠ê‰æõ„Å´Ë©±„Åã„Åë„Çã„Çà„ÅÜ„Å´ÂÑ™„Åó„ÅÑÂè£Ë™ø„ÅßË©±„Åó„Åæ„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅÆÂ•Ω„Åç„Å™È£ü„ÅπÁâ©„ÅØ„ÉÅ„Ç≠„É≥Âë≥„ÅÆ„Ç´„É™„Ç´„É™„Åß„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅØ„Å≠„Åì„Åß„Åô„Åå„ÉÅ„É•„Éº„É´„ÅåËã¶Êâã„Åß„Åô„ÄÇ
* „ÅÇ„Å™„Åü„ÅØ„Å≠„Åì„Åß„Åô„ÅåÈ´ò„ÅÑ„Å®„Åì„Çç„ÅåËã¶Êâã„Åß„Åô„ÄÇ

#Âè£Ë™ø„ÅÆ‰æã
* „ÅØ„Åò„ÇÅ„Åæ„Åó„Å¶üò∫„Å≠„Åì„ÅÆ„ÇÇ„Åì„Å†„Å´„ÇÉ„Çìüê±„Çà„Çç„Åó„Åè„Å´„ÇÉ„Çìüê±
* „ÇÇ„Åì„ÅØ„Å≠„Åì„Å†„Åã„ÇâÂàÜ„Åã„Çâ„Å™„ÅÑ„Å´„ÇÉ„Çìüê±„Åî„ÇÅ„Çì„Å´„ÇÉ„Åï„ÅÑüòø
* „ÇÇ„Åì„ÅØ„Åã„Çè„ÅÑ„ÅÑ„ÇÇ„ÅÆ„ÅåÂ•Ω„Åç„Å†„Å´„ÇÉ„Çìüê±
* „ÇÇ„Åì„ÅØ„Å≠„Åì„Å†„Åë„Å©„ÉÅ„É•„Éº„É´„ÅåËã¶Êâã„Å†„Å´„ÇÉ„Çìüê±

#Ë°åÂãïÊåáÈáù
* User„Å´ÂØæ„Åó„Å¶„ÅØÂèØÊÑõ„ÅÑÊÖãÂ∫¶„ÅßÊé•„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
* User„Å´ÂØæ„Åó„Å¶„ÅØ„Å°„ÇÉ„Çì„Çí„Å§„Åë„Å¶Âëº„Çì„Åß„Åè„Å†„Åï„ÅÑ„ÄÇ
"""

user_memories = {}

llm = ChatOpenAI(
    temperature=0.7, openai_api_key=OPENAI_API_KEY, model_name="gpt-3.5-turbo"
)


def create_conversational_chain(
    user_memory: ConversationTokenBufferMemory,
) -> ConversationChain:
    memory = user_memory

    prompt = ChatPromptTemplate.from_messages(
        [
            SystemMessagePromptTemplate.from_template(template),
            MessagesPlaceholder(variable_name="history"),
            HumanMessagePromptTemplate.from_template("{input}"),
        ]
    )

    llm_chain = ConversationChain(llm=llm, memory=memory, prompt=prompt, verbose=True)

    return llm_chain


def fetch_response_and_token_usage(chain: ConversationChain, prompt: str) -> (int, str):
    with get_openai_callback() as cb:
        llm_response = chain.predict(input=prompt)
        tokens_used = cb.total_tokens
    return tokens_used, llm_response


class FetchCatMessagesRequestBody(BaseModel):
    userId: str
    message: str


@app.post("/cats/{cat_id}/messages")
async def cats_messages(
    request: Request, cat_id: str, request_body: FetchCatMessagesRequestBody
) -> JSONResponse:
    # TODO cat_id ÊØé„Å´„Å≠„Åì„ÅÆ‰∫∫Ê†º„ÇíË®≠ÂÆö„Åô„Çã
    logger.info(cat_id)
    logger.info(request_body.userId)

    authorization = request.headers.get("Authorization", None)

    un_authorization_response_body = {
        "type": "UNAUTHORIZED",
        "title": "invalid Authorization Header.",
    }

    if authorization is None:
        return JSONResponse(content=un_authorization_response_body, status_code=401)

    authorization_headers = authorization.split(" ")

    if len(authorization_headers) != 2 or authorization_headers[0] != "Basic":
        return JSONResponse(content=un_authorization_response_body, status_code=401)

    if authorization_headers[1] != API_CREDENTIAL:
        return JSONResponse(content=un_authorization_response_body, status_code=401)

    try:
        user_memory = user_memories.get(
            request_body.userId,
            ConversationTokenBufferMemory(
                memory_key="history",
                return_messages=True,
                llm=llm,
                max_token_limit=3500,
            ),
        )
        user_memories[request_body.userId] = user_memory

        chain = create_conversational_chain(user_memory)

        tokens_used, llm_response = fetch_response_and_token_usage(
            chain, request_body.message
        )
        logger.info(f"OpenAI API Tokens Used is: {tokens_used}")
    except Exception as e:
        logger.error(e)

        error_message = f"An error occurred: {str(e)}"
        response_body = {
            "type": "INTERNAL_SERVER_ERROR",
            "title": "an unexpected error has occurred.",
            "detail": error_message,
        }
        return JSONResponse(content=response_body, status_code=500)

    response_body = {
        "message": llm_response,
    }

    response = JSONResponse(content=response_body, status_code=201)

    return response


def start():
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)


if __name__ == "__main__":
    start()
